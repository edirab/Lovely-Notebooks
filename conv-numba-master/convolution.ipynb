{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import cuda\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def slow_kernel(inputImage, kernel, outputImage, channels, w, h, kernelRows, kernelCols):\n",
    "    r, c = cuda.grid(2) # Finding the global position of the thread\n",
    "    kernelRowsRadius = kernelRows//2\n",
    "    kernelColsRadius = kernelCols//2\n",
    "    for b in range(BATCH):\n",
    "        for ch in range(channels):\n",
    "            opPixel = 0\n",
    "            if r < h and c < w:\n",
    "                startRow = r - kernelRowsRadius\n",
    "                startCol = c - kernelColsRadius\n",
    "                for i in range(kernelRows):\n",
    "                    for j in range(kernelCols):\n",
    "                        currentRow = startRow + i\n",
    "                        currentCol = startCol + j\n",
    "                        if currentRow >= 0 and currentRow < h and currentCol >= 0 and currentCol < w:\n",
    "                            opPixel += inputImage[b, currentRow, currentCol, ch]*kernel[i, j]\n",
    "            outputImage[b,r,c,ch] = opPixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('peacock.jpg')\n",
    "# img = cv2.resize(img, (imgrows, imgcols))\n",
    "# img_batch = []\n",
    "# for i in range(BATCH):\n",
    "#     img_batch.append(img)\n",
    "# img_batch = np.array(img_batch)\n",
    "# threadsperblock = (16, 16)\n",
    "# blockspergrid = (np.ceil(imgrows/threadsperblock[0]).astype('int'), np.ceil(imgcols/threadsperblock[1]).astype('int'))\n",
    "# print (threadsperblock)\n",
    "# print (blockspergrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "imgrows = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "imgcols = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# imgrows = 2**7\n",
    "# imgcols = 2**7\n",
    "\n",
    "BATCH = 100\n",
    "# BATCH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "img_batch = []\n",
    "for i in range(BATCH):\n",
    "    ret, img = cap.read()\n",
    "#     img = cv2.resize(img, (imgrows, imgcols))\n",
    "    img_batch.append(img)\n",
    "img_batch = np.array(img_batch)\n",
    "threadsperblock = (16, 16)\n",
    "blockspergrid = (np.ceil(imgcols/threadsperblock[0]).astype('int'), np.ceil(imgrows/threadsperblock[1]).astype('int'))\n",
    "print (threadsperblock)\n",
    "print (blockspergrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average\n",
    "kernelwidth =  7\n",
    "kernelheight = 7\n",
    "kernel = np.ones((kernelwidth,kernelheight))\n",
    "kernel /= kernelheight*kernelwidth\n",
    "KERNEL_CONSTANT = kernel.copy()\n",
    "### Laplacian\n",
    "# kernel = np.array([[-1,-1,-1], [-1, 8 ,-1],[-1,-1,-1]]) \n",
    "\n",
    "### sharpen\n",
    "# kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]]) \n",
    "\n",
    "# Edge detection\n",
    "# kernel = np.array([[0,1,0], [1,-4,1], [0,1,0]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6d40e8d3c443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mkernelGlobalMemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0moutputImageGlobalMemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mimgcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mslow_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblockspergrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreadsperblock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImageGlobalMemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernelGlobalMemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputImageGlobalMemory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernelwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernelheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# outputImage = outputImageGlobalMemory.copy_to_host()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# stop.record()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[0mSpecialize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minvoke\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         '''\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36mspecialize\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    812\u001b[0m         '''\n\u001b[0;32m    813\u001b[0m         argtypes = tuple(\n\u001b[1;32m--> 814\u001b[1;33m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[0m\u001b[0;32m    815\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    812\u001b[0m         '''\n\u001b[0;32m    813\u001b[0m         argtypes = tuple(\n\u001b[1;32m--> 814\u001b[1;33m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[0m\u001b[0;32m    815\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\typing\\context.py\u001b[0m in \u001b[0;36mresolve_argument_type\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \"\"\"\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtypeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPurpose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnumba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cuda_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\typing\\typeof.py\u001b[0m in \u001b[0;36mtypeof\u001b[1;34m(val, purpose)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Note the behaviour for Purpose.argument must match _typeof.c.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_TypeofContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpurpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtypeof_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mty\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         msg = _termcolor.errmsg(\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    838\u001b[0m                             '1 positional argument')\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__name__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'singledispatch function'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\typing\\typeof.py\u001b[0m in \u001b[0;36mtypeof_impl\u001b[1;34m(val, c)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_numba_type_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py\u001b[0m in \u001b[0;36m_numba_type_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mlayout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'A'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\numpy_support.py\u001b[0m in \u001b[0;36mfrom_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNestedArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: object"
     ]
    }
   ],
   "source": [
    "# stream = cuda.stream()\n",
    "# start = time.time()\n",
    "# with stream.auto_synchronize():\n",
    "channels = 3\n",
    "# start = cuda.event(timing = True)\n",
    "# stop = cuda.event(timing = True)\n",
    "# start.record()\n",
    "inputImageGlobalMemory = cuda.to_device(img_batch)\n",
    "kernelGlobalMemory = cuda.to_device(kernel)\n",
    "outputImageGlobalMemory = cuda.device_array((BATCH ,imgcols, imgrows, channels))\n",
    "slow_kernel[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,channels, imgrows, imgcols, kernelwidth, kernelheight)\n",
    "# outputImage = outputImageGlobalMemory.copy_to_host()\n",
    "# stop.record()\n",
    "# To make executions async and when python exits the context\n",
    "# syncronization happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start.record()\n",
    "# slow_kernel[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,1, imgrows, imgcols, kernelwidth, kernelheight)\n",
    "# stop.record()\n",
    "\n",
    "outputImage = outputImageGlobalMemory.copy_to_host()\n",
    "# print (start.elapsed_time(stop)*1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_batch[55][:,:,::-1])\n",
    "plt.title(\"Input Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(outputImage[55][:,:,::-1].astype('uint8'))\n",
    "plt.title(\"Processed in GPU\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streams = 4\n",
    "streams = []\n",
    "CHANNEL = 3\n",
    "\n",
    "# Creating a list of streams for Spatio Temporal parallelism\n",
    "for i in range(n_streams):\n",
    "    streams.append(cuda.stream())\n",
    "\n",
    "\n",
    "# start = cuda.event(timing = True)\n",
    "# stop = cuda.event(timing = True)\n",
    "\n",
    "# Pumping data from CPU to GPU\n",
    "for i in streams:\n",
    "    \n",
    "    inputImageGlobalMemory = cuda.to_device(img_batch,stream=i)\n",
    "\n",
    "# start.record()\n",
    "# Starting kernel Calls in CUDA streams \n",
    "for k in streams:\n",
    "    kernelGlobalMemory = cuda.to_device(KERNEL_CONSTANT,stream=k)\n",
    "    outputImageGlobalMemory = cuda.device_array((BATCH, imgrows, imgcols, CHANNEL),stream=k)\n",
    "    # shared_conv[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,1, imgrows, imgcols)\n",
    "    slow_kernel[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,CHANNEL, imgrows, imgcols, kernelwidth, kernelheight)\n",
    "# stop.record()\n",
    "\n",
    "# Getting data back to GPU from CPU\n",
    "outputImage = outputImageGlobalMemory.copy_to_host()\n",
    "# print (start.elapsed_time(stop)*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(group_number):\n",
    "    cap = cv2.VideoCapture(args.input_file)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_jump_unit * group_number)\n",
    "    proc_frames = 0\n",
    "    out = cv2.VideoWriter(\n",
    "        \"{}.{}\".format(group_number, args.extension),\n",
    "        cv2.VideoWriter_fourcc(*vid_fourcc[args.extension]),\n",
    "        fps,\n",
    "        (width, height),\n",
    "    )\n",
    "\n",
    "    while proc_frames < frame_jump_unit:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        out.write(cv2.filter2D(frame, -1, kernel))\n",
    "        proc_frames += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "(0, 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't copy sequence with size 0 to array axis 3 with dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b7b7febf2c7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mproc_frames\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0minputImageGlobalMemory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Input Streams \"\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[1;34m(*args, **kws)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdevices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_setitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py\u001b[0m in \u001b[0;36m_do_setitem\u001b[1;34m(self, key, value, stream)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     l))\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;31m# (3) do the copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't copy sequence with size 0 to array axis 3 with dimension 3"
     ]
    }
   ],
   "source": [
    "n_streams = 10\n",
    "streams = []\n",
    "CHANNEL = 3\n",
    "cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "frame_jump_unit = cap.get(cv2.CAP_PROP_FRAME_COUNT) // n_streams\n",
    "BATCH = int(frame_jump_unit)\n",
    "\n",
    "imgrows = int(width)\n",
    "imgcols = int(height)\n",
    "\n",
    "threadsperblock = (16, 16)\n",
    "# blockspergrid = (np.ceil(imgrows/threadsperblock[0]).astype('int'), np.ceil(imgcols/threadsperblock[1]).astype('int'))\n",
    "blockspergrid = (np.ceil(imgcols/threadsperblock[0]).astype('int'), np.ceil(imgrows/threadsperblock[1]).astype('int'))\n",
    "print (threadsperblock)\n",
    "print (blockspergrid)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "outputImage = np.ones((int(n_streams), BATCH , imgrows, imgcols, 3)).astype('int')\n",
    "\n",
    "# Creating a list of streams for Spatio Temporal parallelism\n",
    "for i in range(n_streams):\n",
    "    streams.append(cuda.stream())\n",
    "\n",
    "\n",
    "# start = cuda.event(timing = True)\n",
    "# stop = cuda.event(timing = True)\n",
    "\n",
    "# Pumping data from CPU to GPU\n",
    "inputImageGlobalMemory = cuda.device_array((int(n_streams), BATCH , imgrows, imgcols, 3))\n",
    "frame_jump_unit = cap.get(cv2.CAP_PROP_FRAME_COUNT) // n_streams\n",
    "for idx, i in enumerate(streams):\n",
    "    cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_jump_unit) * idx)\n",
    "    proc_frames = 0\n",
    "    img_batch = []\n",
    "    while proc_frames < frame_jump_unit:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (imgrows, imgcols))\n",
    "        img_batch.append(frame)\n",
    "        if ret == False:\n",
    "            break\n",
    "        proc_frames += 1\n",
    "    inputImageGlobalMemory[idx] = cuda.to_device(img_batch,stream=i)\n",
    "    print (\"Input Streams \"  + str(idx))\n",
    "    i.synchronize()\n",
    "\n",
    "# start.record()\n",
    "# Starting kernel Calls in CUDA streams \n",
    "outputImageGlobalMemory = cuda.device_array(( int(n_streams), int(frame_jump_unit), imgrows, imgcols, CHANNEL))\n",
    "for idx,k in enumerate(streams):\n",
    "    kernelGlobalMemory = cuda.to_device(KERNEL_CONSTANT,stream=k)\n",
    "#     outputImageGlobalMemory = cuda.device_array(( int(frame_jump_unit), imgrows, imgcols, CHANNEL),stream=k)\n",
    "    # shared_conv[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,1, imgrows, imgcols)\n",
    "    slow_kernel[blockspergrid, threadsperblock, k](inputImageGlobalMemory[idx], kernelGlobalMemory, outputImageGlobalMemory[idx],CHANNEL, imgrows, imgcols, kernelwidth, kernelheight)\n",
    "    print (\"Kernel Calls \" + str(idx))\n",
    "# stop.record()\n",
    "\n",
    "for idx,k in enumerate(streams):\n",
    "    # Getting data back to GPU from CPU\n",
    "    outputImage[idx] = outputImageGlobalMemory[idx].copy_to_host(stream=k)\n",
    "    print (\"Output Streams \" + str(idx))\n",
    "    out = cv2.VideoWriter(\n",
    "    \"output/{}.{}\".format(str(idx), 'avi'),\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    fps,\n",
    "    (imgrows, imgcols),\n",
    "    )\n",
    "    k.synchronize()\n",
    "    for img_out in outputImage[idx]:\n",
    "        out.write(img_out.astype('uint8'))\n",
    "    out.release()\n",
    "    # print (start.elapsed_time(stop)*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streams = 10\n",
    "streams = []\n",
    "CHANNEL = 3\n",
    "cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "frame_jump_unit = cap.get(cv2.CAP_PROP_FRAME_COUNT) // n_streams\n",
    "BATCH = int(frame_jump_unit)\n",
    "\n",
    "imgrows = int(width)\n",
    "imgcols = int(height)\n",
    "\n",
    "threadsperblock = (16, 16)\n",
    "blockspergrid = (np.ceil(imgrows/threadsperblock[0]).astype('int'), np.ceil(imgcols/threadsperblock[1]).astype('int'))\n",
    "print (threadsperblock)\n",
    "print (blockspergrid)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "outputImage = np.ones((1, BATCH , imgrows, imgcols, 3)).astype('int')\n",
    "\n",
    "# Creating a list of streams for Spatio Temporal parallelism\n",
    "for i in range(n_streams):\n",
    "    streams.append(cuda.stream())\n",
    "\n",
    "\n",
    "# start = cuda.event(timing = True)\n",
    "# stop = cuda.event(timing = True)\n",
    "\n",
    "# Pumping data from CPU to GPU\n",
    "inputImageGlobalMemory = cuda.device_array((int(n_streams), BATCH , imgrows, imgcols, 3))\n",
    "outputImageGlobalMemory = cuda.device_array(( int(n_streams), int(frame_jump_unit), imgrows, imgcols, CHANNEL))\n",
    "frame_jump_unit = cap.get(cv2.CAP_PROP_FRAME_COUNT) // n_streams\n",
    "for idx, i in enumerate(streams):\n",
    "    print (\"Opening CAP\")\n",
    "    cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_jump_unit) * idx)\n",
    "    proc_frames = 0\n",
    "    img_batch = []\n",
    "    print (\"starting to load\")\n",
    "    while proc_frames < frame_jump_unit:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (imgrows, imgcols))\n",
    "        img_batch.append(frame)\n",
    "        if ret == False:\n",
    "            break\n",
    "        proc_frames += 1\n",
    "    print (\"Done Loafing\")\n",
    "    inputImageGlobalMemory[idx] = cuda.to_device(img_batch,stream=i)\n",
    "    print (\"Input Streams \"  + str(idx))\n",
    "#     i.synchronize()\n",
    "\n",
    "    kernelGlobalMemory = cuda.to_device(KERNEL_CONSTANT,stream=i)\n",
    "    # shared_conv[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,1, imgrows, imgcols)\n",
    "    slow_kernel[blockspergrid, threadsperblock, i](inputImageGlobalMemory[idx], kernelGlobalMemory, outputImageGlobalMemory[idx],CHANNEL, imgrows, imgcols, kernelwidth, kernelheight)\n",
    "    print (\"Kernel Calls \" + str(idx))\n",
    "\n",
    "    # Getting data back to GPU from CPU\n",
    "    outputImage[0] = outputImageGlobalMemory[idx].copy_to_host(stream=i)\n",
    "    print (\"Output Streams \" + str(idx))\n",
    "    out = cv2.VideoWriter(\n",
    "    \"output/{}.{}\".format(str(idx), 'avi'),\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    fps,\n",
    "    (imgrows, imgcols),\n",
    "    )\n",
    "    i.synchronize()\n",
    "    for img_out in outputImage[idx]:\n",
    "        out.write(img_out.astype('uint8'))\n",
    "    out.release()\n",
    "    # print (start.elapsed_time(stop)*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streams = 10\n",
    "streams = []\n",
    "CHANNEL = 3\n",
    "cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "frame_jump_unit = cap.get(cv2.CAP_PROP_FRAME_COUNT) // n_streams\n",
    "BATCH = int(frame_jump_unit)\n",
    "\n",
    "imgrows = int(width)\n",
    "imgcols = int(height)\n",
    "\n",
    "threadsperblock = (16, 16)\n",
    "\n",
    "# blockspergrid = (np.ceil(imgrows/threadsperblock[1]).astype('int'), np.ceil(imgcols/threadsperblock[0]).astype('int'))\n",
    "blockspergrid = (np.ceil(imgcols/threadsperblock[0]).astype('int'), np.ceil(imgrows/threadsperblock[1]).astype('int'))\n",
    "print (threadsperblock)\n",
    "print (blockspergrid)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "outputImage = np.ones((1, BATCH , imgcols, imgrows, 3)).astype('int')\n",
    "\n",
    "# start = cuda.event(timing = True)\n",
    "# stop = cuda.event(timing = True)\n",
    "\n",
    "# Pumping data from CPU to GPU\n",
    "inputImageGlobalMemory = cuda.device_array((1, BATCH , imgcols, imgrows, 3))\n",
    "outputImageGlobalMemory = cuda.device_array(( 1, int(frame_jump_unit), imgcols, imgrows, CHANNEL))\n",
    "frame_jump_unit = cap.get(cv2.CAP_PROP_FRAME_COUNT) // n_streams\n",
    "for idx in range(n_streams):\n",
    "    print (\"Opening CAP\")\n",
    "    cap = cv2.VideoCapture('Kiiara.mp4')\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_jump_unit) * idx)\n",
    "    proc_frames = 0\n",
    "    img_batch = []\n",
    "    print (\"starting to load\")\n",
    "    while proc_frames < frame_jump_unit:\n",
    "        ret, frame = cap.read()\n",
    "#         print (frame.shape)\n",
    "#         frame = cv2.resize(frame, (imgrows, imgcols))\n",
    "        img_batch.append(frame)\n",
    "        if ret == False:\n",
    "            break\n",
    "        proc_frames += 1\n",
    "    print (\"Done Loafing\")\n",
    "    print (np.array(img_batch).shape)\n",
    "    inputImageGlobalMemory[0] = cuda.to_device(img_batch)\n",
    "    print (\"Input Streams \"  + str(idx))\n",
    "#     i.synchronize()\n",
    "\n",
    "    kernelGlobalMemory = cuda.to_device(KERNEL_CONSTANT)\n",
    "    # shared_conv[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,1, imgrows, imgcols)\n",
    "    slow_kernel[blockspergrid, threadsperblock](inputImageGlobalMemory[0], kernelGlobalMemory, outputImageGlobalMemory[0],CHANNEL, imgrows, imgcols, kernelwidth, kernelheight)\n",
    "    print (\"Kernel Calls \" + str(0))\n",
    "\n",
    "    # Getting data back to GPU from CPU\n",
    "    outputImage[0] = outputImageGlobalMemory[0].copy_to_host()\n",
    "    print (\"Output Streams \" + str(idx))\n",
    "    out = cv2.VideoWriter(\n",
    "    \"output/{}.{}\".format(str(idx), 'avi'),\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    fps,\n",
    "    (imgrows, imgcols),\n",
    "    )\n",
    "    for img_out in outputImage[0]:\n",
    "#         plt.imshow(img_out)\n",
    "#         plt.show()\n",
    "        out.write(img_out.astype('uint8'))\n",
    "    out.release()\n",
    "    cuda.current_context().deallocations.clear()\n",
    "    # print (start.elapsed_time(stop)*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "intermediate_files = [\"{}.{}\".format(i, \"avi\") for i in range(4)]\n",
    "with open(\"intermediate_files.txt\", \"w\") as f:\n",
    "    for t in intermediate_files:\n",
    "        f.write(\"file {} \\n\".format(t))\n",
    "\n",
    "ffmpeg_command = \"ffmpeg -y -loglevel error -f concat -safe 0 -i intermediate_files.txt\".format().strip()\n",
    "# if args.x264 == False:\n",
    "ffmpeg_command += \" -vcodec copy\"\n",
    "# else:\n",
    "#     ffmpeg_command += \" -vcodec libx264\"\n",
    "ffmpeg_command += \" output_method2.{}\".format('avi')\n",
    "t2 = time.time()\n",
    "sp.Popen(ffmpeg_command, shell=True).wait()\n",
    "t3 = time.time()\n",
    "\n",
    "from os import remove\n",
    "\n",
    "for f in intermediate_files:\n",
    "    remove(f)\n",
    "remove(\"intermediate_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = cv2.VideoWriter(\n",
    "    \"{}.{}\".format(str(0), 'avi'),\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    fps,\n",
    "    (imgrows, imgcols),\n",
    "    )\n",
    "for img_out in outputImage[0]:\n",
    "    out.write(img_out.astype('uint8'))\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cv2.imshow(\"iamge\", outputImage[0][750])\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "op_image = []\n",
    "for i in range(BATCH):\n",
    "    op_image.append(cv2.filter2D(img_batch[i],-1,kernel))\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"output.jpg\", outputImage.astype('int'))\n",
    "cv2.imwrite(\"input.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL = 3\n",
    "O_TILE_WIDTH = 8\n",
    "BLOCK_WIDTH =  O_TILE_WIDTH + KERNEL - 1\n",
    "CHANNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Average\n",
    "kernel = np.ones((KERNEL,KERNEL))\n",
    "kernel /= KERNEL*KERNEL\n",
    "\n",
    "## Laplacian\n",
    "# kernel = np.array([[-1,-1,-1], [-1, 8 ,-1],[-1,-1,-1]]) \n",
    "\n",
    "### sharpen\n",
    "# kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]]) \n",
    "\n",
    "# Edge detection\n",
    "# kernel = np.array([[0,1,0], [1,-4,1], [0,1,0]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def shared_conv(inputImage, kernel, outputImage, channels, w, h):\n",
    "    \n",
    "    Ns = cuda.shared.array(shape=(BLOCK_WIDTH, BLOCK_WIDTH), dtype=numba.uint8)\n",
    "    \n",
    "    r, c  = cuda.grid(2)\n",
    "    KERNEL_RADIUS = KERNEL//2\n",
    "    \n",
    "    # Need to load cooperatively [blockDim.x + Kernelrowradius , blockDim.y + Kernelcolsradius]\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Calculating the output tile's row and col coordinates\n",
    "    row_o = cuda.blockIdx.y*O_TILE_WIDTH + ty\n",
    "    col_o = cuda.blockIdx.x*O_TILE_WIDTH + tx\n",
    "    \n",
    "    # Shifting the coordinate system to corresponding input tile \n",
    "    row_i = row_o - KERNEL_RADIUS\n",
    "    col_i = col_o - KERNEL_RADIUS\n",
    "    \n",
    "    output = 0.0\n",
    "    \n",
    "    # Taking care of boundaries\n",
    "    if (row_i >= 0 and row_i < h and col_i >=0  and col_i < w):\n",
    "        Ns[ty][tx] = inputImage[row_i, col_i]\n",
    "    else:\n",
    "        Ns[ty][tx] = 0\n",
    "    \n",
    "    # Some threads do not participate in calclating the output\n",
    "    if (ty < O_TILE_WIDTH and tx < O_TILE_WIDTH):\n",
    "        for i in range(KERNEL):\n",
    "            for j in range(KERNEL):\n",
    "                output+= Ns[i+ty][j+tx]*kernel[i][j]\n",
    "        if row_o < w and col_o < h:\n",
    "            outputImage[row_o, col_o] = output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def shared_conv_color(inputImage, kernel, outputImage, channels, w, h):\n",
    "    \n",
    "    Ns = cuda.shared.array(shape=(BATCH, BLOCK_WIDTH, BLOCK_WIDTH, CHANNEL), dtype=numba.uint8)\n",
    "    \n",
    "    r, c  = cuda.grid(2)\n",
    "    KERNEL_RADIUS = KERNEL//2\n",
    "    \n",
    "    # Need to load cooperatively [blockDim.x + Kernelrowradius , blockDim.y + Kernelcolsradius]\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Calculating the output tile's row and col coordinates\n",
    "    row_o = cuda.blockIdx.y*O_TILE_WIDTH + ty\n",
    "    col_o = cuda.blockIdx.x*O_TILE_WIDTH + tx\n",
    "    \n",
    "    # Shifting the coordinate system to corresponding input tile \n",
    "    row_i = row_o - KERNEL_RADIUS\n",
    "    col_i = col_o - KERNEL_RADIUS\n",
    "    \n",
    "    output = 0.0\n",
    "    \n",
    "    # Taking care of boundaries\n",
    "    if (row_i >= 0 and row_i < h and col_i >=0  and col_i < w):\n",
    "        for b in range(BATCH):\n",
    "            for ch in range(CHANNEL):\n",
    "                Ns[b, ty, tx, ch] = inputImage[b, row_i, col_i, ch]\n",
    "    else:\n",
    "        for b in range(BATCH):\n",
    "            for ch in range(CHANNEL):\n",
    "                Ns[b, ty, tx, ch] = 0\n",
    "    \n",
    "    # Some threads do not participate in calclating the output\n",
    "    for b in range(BATCH):\n",
    "        for ch in range(CHANNEL):\n",
    "            output = 0.0\n",
    "            if (ty < O_TILE_WIDTH and tx < O_TILE_WIDTH):\n",
    "                for i in range(KERNEL):\n",
    "                    for j in range(KERNEL):\n",
    "                        output+= Ns[b, i+ty, j+tx, ch]*kernel[i][j]\n",
    "                if row_o < w and col_o < h:\n",
    "                    outputImage[b, row_o, col_o, ch] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('peacock.jpg')\n",
    "img = cv2.resize(img, (imgrows, imgcols))\n",
    "threadsperblock = (BLOCK_WIDTH , BLOCK_WIDTH)\n",
    "blockspergrid = (np.ceil(imgrows/O_TILE_WIDTH).astype('int'), np.ceil(imgcols/O_TILE_WIDTH).astype('int'))\n",
    "print (threadsperblock)\n",
    "print (blockspergrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = cuda.event(timing = True)\n",
    "stop = cuda.event(timing = True)\n",
    "inputImageGlobalMemory = cuda.to_device(img_batch)\n",
    "kernelGlobalMemory = cuda.to_device(kernel)\n",
    "outputImageGlobalMemory = cuda.device_array((BATCH, imgrows, imgcols, CHANNEL))\n",
    "\n",
    "start.record()\n",
    "# shared_conv[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,1, imgrows, imgcols)\n",
    "shared_conv_color[blockspergrid, threadsperblock](inputImageGlobalMemory, kernelGlobalMemory, outputImageGlobalMemory,CHANNEL, imgrows, imgcols)\n",
    "stop.record()\n",
    "\n",
    "outputImage = outputImageGlobalMemory.copy_to_host()\n",
    "print (start.elapsed_time(stop)*1e-3)\n",
    "# To make executions async and when python exits the context\n",
    "# syncronization happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1], cmap='gray')\n",
    "plt.title(\"Input Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(outputImage[0][:,:,::-1].astype('uint8'), cmap='gray')\n",
    "plt.title(\"Processed in GPU\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
